---
title: ""
collection: talks
type: "Talk"
permalink: /talks/list.md
---


<h2 style="color:SteelBlue;" vspace="-60px;"><a id="tutorial">Tutorials:</a></h2>
<hr style="height:1px;border-width:0;color:black;background-color:black">
<ul>
     <li><span style="color:blue">Preference Bandits.</span> Asian Conference of Machine Learning (ACML). November, 2021.</li>
     <li><span style="color:blue">Bandits for Beginners.</span> Microsoft Reactor: Data Science and Machine Learning Track. November, 2021.</li>
     <li><span style="color:blue">Short Tutorial: (1). Support Vector Machines, (2). Winnow and Perceptron Algorithms.</span> M.S. Ramaiah Institute of Technology, Bangalore. May, 2018.</li>
     <li><span style="color:blue">Let's Tame the Bandits!</span> Undergraduate Summer School, CSA department, IISc Bangalore. July 2018.</li>
</ul>
<hr>
\vspace*{-150px}
<h2 style="color:SteelBlue;"><a id="research_talks">Research Talks:</a></h2>
<hr style="height:1px;border-width:0;color:black;background-color:black">
<dl>
  <dt><span style="color:blue">Information Aggregation from Unconventional Feedback</span></dt>
     <dd>Oracle Research, November, 2021.</dd>
     
  <dt><span style="color:blue">Preference based Reinforcement Learning (PbRL)</span></dt>
     <dd>Microsoft Research Tri-Lab Offsite. November, 2021</dd>
     <dd>RL Track, Microsoft Research Summit. October, 2021</dd>
     
  <dt><span style="color:blue">Battling Bandits: Exploiting Subsetwise Preferences</span></dt>   
     <dd>Sabarmati Seminar Series, IIT Gandhinagar. July 2021.</dd>   
     <dd>SIERRA-Seminar, Inria, Paris. January 2020.</dd>   
     <dd>Microsoft Research, Bangalore, India. October 2019.</dd>   
     <dd>EECS department, University of Michigan, Ann Arbor. September, 2019</dd>   
     <dd>Computer Science department, Stanford University, Serra Mall, Stanford. August, 2019</dd>   
     <dd>EECS Symposium, IISc Bangalore. April, 2019.</dd>
     <dd>Carnegie Mellon University (CMU), Pittsburgh. March, 2019</dd>   
     <dd>Qualcomm Research, Bangalore. May, 2018</dd> 
     
  <dt><span style="color:blue">Adversarial Dueling Bandits</span></dt>   
     <dd>Data Science in India, KDD Conference, India, August 2021.</dd>    
     
  <dt><span style="color:blue">Bandits, Experts and Rank Aggregation</span></dt>   
     <dd>TCS Research Lab, Bangalore. June, 2018</dd>   
     <dd>Indian Institute of Technology (IIT) Madras. November, 2018</dd>
     <dd>Amazon, Bangalore. October, 2018</dd>
     <dd>IBM-IRL, Bangalore. July 2018.</dd>
     
  <dt><span style="color:blue">Online Learning with Structured Losses</span></dt>   
     <dd>Conduent Labs, Bangalore. October, 2017.</dd>    
</dl>

<!-- 
<ul>
     <li><span style="color:blue">PbRL: Preference based Reinforcement Learning.</span> RL Track, Microsoft Research Summit. October 2021.</li>
     <li><span style="color:blue">Adversarial Dueling Bandits.</span> Data Science in India, KDD Conference, India. August 2021.</li>
     <li><span style="color:blue">Battle of Bandits.</span> Sabarmati Seminar Series, IIT Gandhinagar, India. July 2021.</li>
     <li><span style="color:blue">Online Learning from Preferences.</span> SIERRA-Seminar, Inria, Paris. January 2020.</li>
     <li><span style="color:blue">Structured Battling Bandits.</span> Microsoft Research, Bangalore, India. October 2019.</li>
</ul>


*3 talks at ICML*, 2021. <br/><br/>
ensp;ensp;<span style="color:blue">Active Ranking with Subset-wise Preferences.</span> *Artificial Intelligence and Statistics (AISTATS)*. Naha, Okinawa, Japan, April 2019.<br/><br/>
<span style="color:blue">PhD Thesis Overview: Information Aggregation from Preferential Feedback.</span> *EECS Symposium, Indian Institute of Science, Bangalore, India*. April 2019.<br/><br/>
<span style="color:blue">PAC Battling-Bandits in the Plackett-Luce model.</span> *Algorithmic Learning Theory (ALT), 2019*. Chicago, USA, March 2019.<br/> 
-->

