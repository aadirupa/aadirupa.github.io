---
title: ""
collection: talks
type: "Talk"
permalink: /talks/list.md
---
<details>
<summary><span style="color:SteelBlue;"> <b>Short Bio</b> [In third person] </span></summary>
<p align="justify"> Aadirupa Saha has been an Assistant Professor in the Department of Computer Science at the University of Illinois Chicago (UIC) since Fall 2025. She is a member of the <a href="https://cstheory.lab.uic.edu/">UIC CS Theory</a> group, as well as <a href="https://www.ideal-institute.org">IDEAL</a> Institute. Prior to this, she was a Research Scientist at Apple MLR, working on Machine Learning theory. She completed her postdoctoral research at Microsoft Research (NYC) and earned her PhD from the Indian Institute of Science (IISc), Bangalore.
<br> <br>
Saha's primary research focuses on AI alignment through Reinforcement Learning with Human Feedback (RLHF), with applications in language models, assistive robotics, autonomous systems, and personalized AI. At a high level, her work aims to develop robust and scalable AI models for designing prediction systems under uncertain and partial feedback.
<br> <br>
<font color="#008000"><b>[Optional] </b></font> Specifically, Saha is deeply motivated by the tremendous potential of AI to democratize learning—reshaping our current education system into a truly adaptive, accessible, and personalized experience for every learner! Driven by this transformative power of generative AI and language models, she envisions building the foundations for equitable, intelligent education systems that turn this vision into reality. Her research focuses on developing futuristic educational models by leveraging her expertise in AI alignment with human feedback, alongside tools from Machine Learning (Online Learning, Bandits, and RL theory), Optimization, Federated Learning, Differential Privacy, and Mechanism Design.
<!--More broadly, she works on Machine Learning theory, including online learning, multi-armed bandits, reinforcement learning, optimization, federated learning, differential privacy, and mechanism design. -->
   <br> <br>
<font color="#008000"><b>[Optional] </b></font> Saha has been a part of several organizational efforts and tutorials over the last few years. Notably, she serves as the communication chair for <a href="https://rl-conference.cc/index.html">RLC, 2026</a>. Besides her community services inlcude a keynote talk at <a href="https://da2pl.ulb.be/">DA2PL Conference</a>, <a href="https://sites.google.com/view/pref-learning-tutorial-neurips/home"> [NeurIPS, 2023] </a> tutorial on Preference Learning, <a href="https://www.youtube.com/watch?v=i3X0Bbep86o" LINK="red">[UAI, 2023] </a> tutorial on Federated Optimization, two tutorials at <a href="https://sites.google.com/view/olpf/home" target="_blank" LINK="red"> [ECML, 2022] </a>, <a href="https://www.acml-conf.org/2021/tutorials/battle-of-bandits-online-learning-from-preference-feedback/" target="_blank" LINK="red"> [ACML, 2021]</a>, three ICML workshops <a href="https://sites.google.com/view/mhf-icml2024" target="_blank" LINK="red"> [ICML, 2024] </a>, <a href="https://sites.google.com/view/mfpl-icml-2023" target="_blank" LINK="red"> [ICML, 2023] </a> and <a href="https://cfol-workshop.github.io/" target="_blank" LINK="red"> [ICML, 2022]</a>, an <a href="https://www.ideal-institute.org/special-programs/" target="_blank" LINK="red"> IDEAL</a> special progrem workshop, and two TTIC workshops  <a href="https://sites.google.com/view/tticfl-summerworkshop2023/home?authuser=0" LINK="red">[TTIC, 2023]</a> and <a href="https://sites.google.com/view/new-ml-model/home" target="_blank" LINK="red">[TTIC, 2022]</a>. In addition, Aadirupa has also served in several panel discussions and senior reviewing committees for major ML conferences. </p>
</details>
<h2 style="color:SteelBlue;" vspace="-60px;"><a id="keynotes">KeyNote:</a></h2>
<hr style="height:1px;border-width:0;color:black;background-color:black"> 
<dl style="margin:0px;margin-bottom:0">
     <dt><span style="color:DarkBlue">Learning Alignment with Human Feedback </span> </dt>
     <dd><a href="https://da2pl.ulb.be/">DA2PL Conferenc</a>, Belgium, April 16-17, 2026.</dd>
</dl>
<hr>
<h2 style="color:SteelBlue;" vspace="-60px;"><a id="tutorial">Tutorials:</a></h2>
<hr style="height:1px;border-width:0;color:black;background-color:black"> 
<dl style="margin:0px;margin-bottom:0">
     <dt><span style="color:DarkBlue">Do you Prefer Learning with Preferences? </span> <a href="https://sites.google.com/view/pref-learning-tutorial-neurips/home">[Tutorial Website]</a> <a href="https://neurips.cc/virtual/2023/tutorial/73950">[NeurIPS Website]</a></dt>
     <dd>With <a href="https://ece.iisc.ac.in/~aditya/" LINK="red"> Aditya Gopalan</a>. Our (amazing) panel: <a href="https://yoshuabengio.org/">Yoshua Bengio</a> · <a href="https://www.cs.toronto.edu/~cebly/">Craig Boutilier</a> · <a href="https://www.ehazan.com/">Elad Hazan</a> · <a href="https://nowak.ece.wisc.edu/">Robert Nowak</a> · <a href="https://www.microsoft.com/en-us/research/people/toschnab/">Tobias Schnabel</a></dd>
     <dd>37th Conference on Neural Information Processing Systems (NeurIPS), New Orleans. Dec 11th, 2023.</dd>
     <dt><span style="color:DarkBlue">Online Optimization meets Federated Learning.</span> <a href="https://www.auai.org/uai2023/tutorials" LINK="red"> [UAI Website] </a> <a href="https://www.youtube.com/watch?v=i3X0Bbep86o" LINK="red"> [Tutorial Recording] </a> </dt> 
     <dd>With <a href="https://kkpatel.ttic.edu/" LINK="red"> Kshitij Kumar Patel</a>, TTIC.</dd>
     <dd> <a href="https://www.auai.org/uai2023/tutorials" LINK="red"> 39th Conference on Uncertainty in Artificial Intelligence (UAI)</a>, Pittsburgh. July 31st, 2023.</dd>
     <dt><span style="color:DarkBlue">ML Beyond Rewards: Online Learning with Preference Feedback.</span>
          <a href="https://sites.google.com/view/olpf/home">[Tutorial Website]</a> </dt> 
     <dd>European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD). September, 2022.</dd>
     <dt><span style="color:DarkBlue">Battle of Bandits: Online learning from Preference Feedback.</span>
     <a href="https://www.acml-conf.org/2021/tutorials/battle-of-bandits-online-learning-from-preference-feedback/">[Tutorial Website]</a></dt> 
     <dd>Asian Conference of Machine Learning (ACML). November, 2021.</dd>
     <dt><span style="color:DarkBlue">Bandits for Beginners.</span><a href="https://www.youtube.com/watch?v=DB06M7ZA0Gs"> [Video link]</a> </dt> 
     <dd>Microsoft Reactor: Data Science and Machine Learning Track. November, 2021.</dd>
     <dt><span style="color:DarkBlue">Preference based RL.</span><a href="https://www.youtube.com/watch?v=MJzBUNtv0Ho"> [Video link]</a> </dt> 
     <dd>RL Track, Microsoft Research Summit. October, 2021.</dd>
     <dt><span style="color:DarkBlue">Short Tutorial: (1). Support Vector Machines, (2). Winnow and Perceptron Algorithms.</span></dt> 
     <dd>M.S. Ramaiah Institute of Technology, Bangalore. May, 2018.</dd>
     <dt><span style="color:DarkBlue">Let's Tame the Bandits!</span><a href="https://www.youtube.com/watch?v=ISRXT6Cu_jw"> [Video link]</a></dt>
     <dd style="margin-bottom:0">Undergraduate Summer School, CSA department, IISc Bangalore. July 2018.</dd>
</dl>
<hr>
<h2 style="color:SteelBlue;" vspace="-60px;"><a id="panel">Panel:</a></h2>
<hr style="height:1px;border-width:0;color:black;background-color:black">
<dl style="margin:0px;margin-bottom:0">
     <dt><span style="color:DarkBlue">Preference based Learning through a Critical Lens</span>
          <a href="https://sites.google.com/view/pref-learning-tutorial-neurips/home">[Tutorial Website]</a> </dt> 
     <dd>Do you Prefer Learning with Preferences? (at NeurIPS'24 Tutorial). December, 2023.</dd>
     <dt><span style="color:DarkBlue">Next decade of Federated Learning and role of Theory</span>
          <a href="https://sites.google.com/view/tticfl-summerworkshop2023/home?authuser=0">[Workshop Website]</a> </dt> 
     <dd>New Frontiers in Federated Learning, September, 2023.</dd>
     <dt><span style="color:DarkBlue">Trusted and Trustworthy AI</span>
          <a href="https://ifk.uchicago.edu/events/1440/the-summit-on-ai-in-society/">[Summit Website]</a> </dt> 
     <dd>The Summit on AI in Society at the University of Chicago, October, 2022.</dd>
</dl>
<hr>
<h2 style="color:SteelBlue;vspace:-100px"><a id="research_talks">Invited Talks:</a></h2>
<hr style="height:1px;border-width:0;color:black;background-color:black">
<dl>
  <dt><span style="color:DarkBlue">Principled Methods for Leveraging Human Feedback towards AI Alignment</span></dt>
     <dd><a href="https://www.ideal-institute.org/2024/05/06/ideal-annual-meeting-and-industry-day-2024/">IDEAL Annual Meeting and Industry Day</a>, UIC Chicago. June 2024</dd>
     
  <dt><span style="color:DarkBlue">Online Federated Learning</span></dt>
     <dd><a href="https://simons.berkeley.edu/workshops/federated-collaborative-learning/schedule">Federated and Collaborative Learning Workshop</a>, Simons Institute, UC Berkeley. July 2023 <a href="https://youtu.be/kzU8DzgBBkE?list=PLgKuh-lKre12czv-LXiEMfVU9mtFEciwC&t=1877">[Talk Recording]</a></dd>
   
  <dt><span style="color:DarkBlue">Dueling-Opt: Convex Optimization with Relative Feedback</span></dt>
     <dd> IFDS Seminar, University of Wisconsin–Madison. October, 2022</dd>
     <dd> Fall OSL Seminar, Northwestern University. October, 2022</dd>
     <dd> Research at TTIC Series. Toyota Technological Institute at Chicago (TTIC), October, 2022</dd> 
     <dd> Theory Seminar, CS, Purdue University. November, 2022</dd> 
     <dd> Samueli CS department Seminar, UCLA. June, 2023</dd> 
     
  <dt><span style="color:DarkBlue">Personalized Prediction Models with Federated Human Preferences</span></dt>
     <dd> <a href="https://tilos.ai/">TILOS Seminar</a>, University of California, San Diego. November, 2023 </dd>
     <dd> CATS Seminar, University of Maryland. November, 2023 </dd>
     <dd> ML-Opt Seminar, University of Washington. October, 2023 </dd>
     
  <dt><span style="color:DarkBlue">Efficient and Optimal Algorithms for Contextual Dueling Bandits under Realizability</span></dt>
     <dd> <a href="https://ai.engin.umich.edu/events/2023-ai-symposium/">UMich AI Symposium.</a> October, 2023</dd>
     <dd> Theory-ML Seminar, CS dept, Carnegie Mellon University (CMU). August, 2023</dd>
     <dd> <a href="https://sites.google.com/view/rltheoryseminars/home?authuser=0">RL Theory Seminar.</a> May, 2022 <a href="https://www.youtube.com/watch?v=Ec7EQnYYOe0">[Talk Recording]</a> </dd>
     <dd> Talks at TTIC Series. Toyota Technological Institute at Chicago (TTIC), August, 2022</dd>
     <dd> CS Seminar, Northwestern University. October, 2022</dd>
     <dd> ML Seminar, University of Illinois, Chicago (UIC). October, 2022</dd>
     <dd> University of Illinois Computer Science Speaker Series, UIUC. October, 2022</dd> 
     <dd> ML Seminar, UChicago. October, 2022</dd>
           
  <dt><span style="color:DarkBlue">Adversarial Dueling Bandits</span></dt>
     <dd><a href="https://nasscom.in/ai-gamechangers/">NASSCOM AI Gamechangers.</a> April, 2022</dd> 
     <dd>Data Science in India, KDD Conference, India, August 2021.</dd>    
     
  <dt><span style="color:DarkBlue">Information Aggregation from Unconventional Feedback</span></dt>
     <dd>Oracle Research, November, 2021.</dd>
     <dd>Chalmers University of Technology, November, 2021.</dd>
     
  <dt><span style="color:DarkBlue">Battle for Better: When and How Can We Learn Faster with Subsetwise Preferences?</span></dt>
     <dd>Spring Seminar, UT Austin. March 2023</dd>
     <dd>ISyE Seminar, Goergia Tech. March 2023</dd>
     <dd> The Institute for Data, Econometrics, Algorithms, and Learning (IDEAL) Talk Series. October, 2022</dd>   
     
  <dt><span style="color:DarkBlue">Preference based Reinforcement Learning (PbRL)</span></dt>
     <dd>Microsoft Research Tri-Lab Offsite. November, 2021</dd>
     <dd>RL Track, Microsoft Research Summit. October, 2021</dd>
     
  <dt><span style="color:DarkBlue">Battling Bandits: Exploiting Subsetwise Preferences</span></dt>   
     <dd>SIERRA-Seminar, Inria, Paris. January 2020.</dd>   
     <dd>Microsoft Research, Bangalore, India. October 2019.</dd>   
     <dd>EECS department, University of Michigan, Ann Arbor. September, 2019</dd>   
     <dd>Computer Science department, Stanford University, Serra Mall, Stanford. August, 2019</dd>   
     <dd>EECS Symposium, IISc Bangalore. April, 2019.</dd>
     <dd>Carnegie Mellon University (CMU), Pittsburgh. March, 2019</dd>   
     <dd>Qualcomm Research, Bangalore. May, 2018</dd>      
     
  <dt><span style="color:DarkBlue">Bandits, Experts and Rank Aggregation</span></dt>   
     <dd>TCS Research Lab, Bangalore. June, 2018</dd>   
     <dd>Indian Institute of Technology (IIT) Madras. November, 2018</dd>
     <dd>Amazon, Bangalore. October, 2018</dd>
     <dd>IBM-IRL, Bangalore. July, 2018.</dd>
     
  <dt><span style="color:DarkBlue">Online Learning with Structured Losses</span></dt>   
     <dd>Conduent Labs, Bangalore. October, 2017.</dd>    
</dl>

<!-- 
<ul>
     <li><span style="color:blue">PbRL: Preference based Reinforcement Learning.</span> RL Track, Microsoft Research Summit. October 2021.</li>
     <li><span style="color:blue">Adversarial Dueling Bandits.</span> Data Science in India, KDD Conference, India. August 2021.</li>
     <li><span style="color:blue">Battle of Bandits.</span> Sabarmati Seminar Series, IIT Gandhinagar, India. July 2021.</li>
     <li><span style="color:blue">Online Learning from Preferences.</span> SIERRA-Seminar, Inria, Paris. January 2020.</li>
     <li><span style="color:blue">Structured Battling Bandits.</span> Microsoft Research, Bangalore, India. October 2019.</li>
</ul>


*3 talks at ICML*, 2021. <br/><br/>
ensp;ensp;<span style="color:blue">Active Ranking with Subset-wise Preferences.</span> *Artificial Intelligence and Statistics (AISTATS)*. Naha, Okinawa, Japan, April 2019.<br/><br/>
<span style="color:blue">PhD Thesis Overview: Information Aggregation from Preferential Feedback.</span> *EECS Symposium, Indian Institute of Science, Bangalore, India*. April 2019.<br/><br/>
<span style="color:blue">PAC Battling-Bandits in the Plackett-Luce model.</span> *Algorithmic Learning Theory (ALT), 2019*. Chicago, USA, March 2019.<br/> 
-->

