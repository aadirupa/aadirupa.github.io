---
title: ""
collection: talks
type: "Talk"
permalink: /talks/list.md
---

<details>
<summary><span style="color:SteelBlue;" align="justify"> Short Bio [In third person]</span></summary>
<span class="abstract-text" style="font-size:1em; color:Black; text-align: justify">
<p align="justify">Aadirupa Saha is an Assistant Professor in the Department of Computer Science at the University of Illinois Chicago (UIC). Prior to this, she was a Research Scientist at Apple MLR, working on Machine Learning theory, and a short-term visiting faculty at the Toyota Technological Institute at Chicago (TTIC). She completed her postdoctoral research at Microsoft Research New York City and earned her PhD from the Indian Institute of Science, Bangalore, advised by Aditya Gopalan and Chiranjib Bhattacharyya. She has also interned at Microsoft Research Bangalore, Inria Paris, and Google AI Mountain View.
    <br>
Her primary research focuses on AI alignment through Reinforcement Learning with Human Feedback (RLHF), with applications in language models, assistive robotics, autonomous systems, and personalized AI. More broadly, she works on Machine Learning theory, including online learning, multi-armed bandits, reinforcement learning, optimization, federated learning, differential privacy, and mechanism design. Her research aims to develop robust and scalable AI models for sequential decision-making under uncertain and partial feedback.    
    <br>
Aadirupa has organized several workshops and tutorials in recent years, including a <a href="https://sites.google.com/view/pref-learning-tutorial-neurips/home"> [NeurIPS, 2023] </a> tutorial on Preference Learning, a  <a href="https://www.youtube.com/watch?v=i3X0Bbep86o" LINK="red">[UAI, 2023] ]</a> tutorial on Federated Optimization, two tutorials at <a href="https://sites.google.com/view/olpf/home" target="_blank" LINK="red"> [ECML, 2022] </a>, <a href="https://www.acml-conf.org/2021/tutorials/battle-of-bandits-online-learning-from-preference-feedback/" target="_blank" LINK="red"> [ACML, 2021]</a>, two ICML workshops <a href="https://sites.google.com/view/mfpl-icml-2023" target="_blank" LINK="red"> [ICML, 2023] </a> and <a href="https://cfol-workshop.github.io/" target="_blank" LINK="red"> [ICML, 2022]</a>, and two TTIC workshops  <a href="https://sites.google.com/view/tticfl-summerworkshop2023/home?authuser=0" LINK="red">[TTIC, 2023]</a> and <a href="https://sites.google.com/view/new-ml-model/home" target="_blank" LINK="red">[TTIC, 2022]</a>. She has also served in different panel discussions and reviewing committees. </p>
</span>
</details>

<!-- <a href="https://www.dropbox.com/scl/fi/mk97cug7omc6icdfz3htx/aadirupa-cv-web.pdf?rlkey=w7un7napmd6eoh25yc61ghn19&dl=0" target="_blank">[Brief Resume]</a> (Last updated: Oct 15, 2023) -->

<hr style="height:1px;border-width:0;color:black;background-color:black"> 

<h2 style="color:SteelBlue;" vspace="-60px;"><a id="tutorial">Tutorials:</a></h2>
<hr style="height:1px;border-width:0;color:black;background-color:black"> 
<dl style="margin:0px;margin-bottom:0">
     <dt><span style="color:DarkBlue">Do you Prefer Learning with Preferences? </span> <a href="https://sites.google.com/view/pref-learning-tutorial-neurips/home">[Tutorial Website]</a> <a href="https://neurips.cc/virtual/2023/tutorial/73950">[NeurIPS Website]</a></dt>
     <dd>With <a href="https://ece.iisc.ac.in/~aditya/" LINK="red"> Aditya Gopalan</a>. Our (amazing) panel: <a href="https://yoshuabengio.org/">Yoshua Bengio</a> · <a href="https://www.cs.toronto.edu/~cebly/">Craig Boutilier</a> · <a href="https://www.ehazan.com/">Elad Hazan</a> · <a href="https://nowak.ece.wisc.edu/">Robert Nowak</a> · <a href="https://www.microsoft.com/en-us/research/people/toschnab/">Tobias Schnabel</a></dd>
     <dd>37th Conference on Neural Information Processing Systems (NeurIPS), New Orleans. Dec 11th, 2023.</dd>
     <dt><span style="color:DarkBlue">Online Optimization meets Federated Learning.</span> <a href="https://www.auai.org/uai2023/tutorials" LINK="red"> [UAI Website] </a> <a href="https://www.youtube.com/watch?v=i3X0Bbep86o" LINK="red"> [Tutorial Recording] </a> </dt> 
     <dd>With <a href="https://kkpatel.ttic.edu/" LINK="red"> Kshitij Kumar Patel</a>, TTIC.</dd>
     <dd> <a href="https://www.auai.org/uai2023/tutorials" LINK="red"> 39th Conference on Uncertainty in Artificial Intelligence (UAI)</a>, Pittsburgh. July 31st, 2023.</dd>
     <dt><span style="color:DarkBlue">ML Beyond Rewards: Online Learning with Preference Feedback.</span>
          <a href="https://sites.google.com/view/olpf/home">[Tutorial Website]</a> </dt> 
     <dd>European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML-PKDD). September, 2022.</dd>
     <dt><span style="color:DarkBlue">Battle of Bandits: Online learning from Preference Feedback.</span>
     <a href="https://www.acml-conf.org/2021/tutorials/battle-of-bandits-online-learning-from-preference-feedback/">[Tutorial Website]</a></dt> 
     <dd>Asian Conference of Machine Learning (ACML). November, 2021.</dd>
     <dt><span style="color:DarkBlue">Bandits for Beginners.</span><a href="https://www.youtube.com/watch?v=DB06M7ZA0Gs"> [Video link]</a> </dt> 
     <dd>Microsoft Reactor: Data Science and Machine Learning Track. November, 2021.</dd>
     <dt><span style="color:DarkBlue">Preference based RL.</span><a href="https://www.youtube.com/watch?v=MJzBUNtv0Ho"> [Video link]</a> </dt> 
     <dd>RL Track, Microsoft Research Summit. October, 2021.</dd>
     <dt><span style="color:DarkBlue">Short Tutorial: (1). Support Vector Machines, (2). Winnow and Perceptron Algorithms.</span></dt> 
     <dd>M.S. Ramaiah Institute of Technology, Bangalore. May, 2018.</dd>
     <dt><span style="color:DarkBlue">Let's Tame the Bandits!</span><a href="https://www.youtube.com/watch?v=ISRXT6Cu_jw"> [Video link]</a></dt>
     <dd style="margin-bottom:0">Undergraduate Summer School, CSA department, IISc Bangalore. July 2018.</dd>
</dl>
<hr>
<h2 style="color:SteelBlue;" vspace="-60px;"><a id="panel">Panel:</a></h2>
<hr style="height:1px;border-width:0;color:black;background-color:black">
<dl style="margin:0px;margin-bottom:0">
     <dt><span style="color:DarkBlue">Preference based Learning through a Critical Lens</span>
          <a href="https://sites.google.com/view/pref-learning-tutorial-neurips/home">[Tutorial Website]</a> </dt> 
     <dd>Do you Prefer Learning with Preferences? (at NeurIPS'24 Tutorial). December, 2023.</dd>
     <dt><span style="color:DarkBlue">Next decade of Federated Learning and role of Theory</span>
          <a href="https://sites.google.com/view/tticfl-summerworkshop2023/home?authuser=0">[Workshop Website]</a> </dt> 
     <dd>New Frontiers in Federated Learning, September, 2023.</dd>
     <dt><span style="color:DarkBlue">Trusted and Trustworthy AI</span>
          <a href="https://ifk.uchicago.edu/events/1440/the-summit-on-ai-in-society/">[Summit Website]</a> </dt> 
     <dd>The Summit on AI in Society at the University of Chicago, October, 2022.</dd>
</dl>
<hr>
<h2 style="color:SteelBlue;vspace:-100px"><a id="research_talks">Invited Talks:</a></h2>
<hr style="height:1px;border-width:0;color:black;background-color:black">
<dl>
  <dt><span style="color:DarkBlue">Principled Methods for Leveraging Human Feedback towards AI Alignment</span></dt>
     <dd><a href="https://www.ideal-institute.org/2024/05/06/ideal-annual-meeting-and-industry-day-2024/">IDEAL Annual Meeting and Industry Day</a>, UIC Chicago. June 2024</dd>
     
  <dt><span style="color:DarkBlue">Online Federated Learning</span></dt>
     <dd><a href="https://simons.berkeley.edu/workshops/federated-collaborative-learning/schedule">Federated and Collaborative Learning Workshop</a>, Simons Institute, UC Berkeley. July 2023 <a href="https://youtu.be/kzU8DzgBBkE?list=PLgKuh-lKre12czv-LXiEMfVU9mtFEciwC&t=1877">[Talk Recording]</a></dd>
   
  <dt><span style="color:DarkBlue">Dueling-Opt: Convex Optimization with Relative Feedback</span></dt>
     <dd> IFDS Seminar, University of Wisconsin–Madison. October, 2022</dd>
     <dd> Fall OSL Seminar, Northwestern University. October, 2022</dd>
     <dd> Research at TTIC Series. Toyota Technological Institute at Chicago (TTIC), October, 2022</dd> 
     <dd> Theory Seminar, CS, Purdue University. November, 2022</dd> 
     <dd> Samueli CS dept Seminar, UCLA. June, 2023</dd> 
     
  <dt><span style="color:DarkBlue">Personalized Prediction Models with Federated Human Preferences</span></dt>
     <dd> <a href="https://tilos.ai/">TILOS Seminar</a>, University of California, San Diego. November, 2023 </dd>
     <dd> CATS Seminar, University of Maryland. November, 2023 </dd>
     <dd> ML-Opt Seminar, University of Washington. October, 2023 </dd>
     
  <dt><span style="color:DarkBlue">Efficient and Optimal Algorithms for Contextual Dueling Bandits under Realizability</span></dt>
     <dd> <a href="https://ai.engin.umich.edu/events/2023-ai-symposium/">UMich AI Symposium.</a> October, 2023</dd>
     <dd> Theory-ML Seminar, CS dept, Carnegie Mellon University (CMU). August, 2023</dd>
     <dd> <a href="https://sites.google.com/view/rltheoryseminars/home?authuser=0">RL Theory Seminar.</a> May, 2022 <a href="https://www.youtube.com/watch?v=Ec7EQnYYOe0">[Talk Recording]</a> </dd>
     <dd> Talks at TTIC Series. Toyota Technological Institute at Chicago (TTIC), August, 2022</dd>
     <dd> CS Seminar, Northwestern University. October, 2022</dd>
     <dd> ML Seminar, University of Illinois, Chicago (UIC). October, 2022</dd>
     <dd> University of Illinois Computer Science Speaker Series, UIUC. October, 2022</dd> 
     <dd> ML Seminar, UChicago. October, 2022</dd>
           
  <dt><span style="color:DarkBlue">Adversarial Dueling Bandits</span></dt>
     <dd><a href="https://nasscom.in/ai-gamechangers/">NASSCOM AI Gamechangers.</a> April, 2022</dd> 
     <dd>Data Science in India, KDD Conference, India, August 2021.</dd>    
     
  <dt><span style="color:DarkBlue">Information Aggregation from Unconventional Feedback</span></dt>
     <dd>Oracle Research, November, 2021.</dd>
     <dd>Chalmers University of Technology, November, 2021.</dd>
     
  <dt><span style="color:DarkBlue">Battle for Better: When and How Can We Learn Faster with Subsetwise Preferences?</span></dt>
     <dd>Bangalore Theory Seminar, IISc Bangalore. October, 2023</dd>
     <dd>Spring Seminar, UT Austin. March 2023</dd>
     <dd>ISyE Seminar, Goergia Tech. March 2023</dd>
     <dd> The Institute for Data, Econometrics, Algorithms, and Learning (IDEAL) Talk Series. October, 2022</dd>   
     
  <dt><span style="color:DarkBlue">Preference based Reinforcement Learning (PbRL)</span></dt>
     <dd>Microsoft Research Tri-Lab Offsite. November, 2021</dd>
     <dd>RL Track, Microsoft Research Summit. October, 2021</dd>
     
  <dt><span style="color:DarkBlue">Battling Bandits: Exploiting Subsetwise Preferences</span></dt>   
     <dd>Sabarmati Seminar Series, IIT Gandhinagar. July 2021.</dd>   
     <dd>SIERRA-Seminar, Inria, Paris. January 2020.</dd>   
     <dd>Microsoft Research, Bangalore, India. October 2019.</dd>   
     <dd>EECS department, University of Michigan, Ann Arbor. September, 2019</dd>   
     <dd>Computer Science department, Stanford University, Serra Mall, Stanford. August, 2019</dd>   
     <dd>EECS Symposium, IISc Bangalore. April, 2019.</dd>
     <dd>Carnegie Mellon University (CMU), Pittsburgh. March, 2019</dd>   
     <dd>Qualcomm Research, Bangalore. May, 2018</dd>      
     
  <dt><span style="color:DarkBlue">Bandits, Experts and Rank Aggregation</span></dt>   
     <dd>TCS Research Lab, Bangalore. June, 2018</dd>   
     <dd>Indian Institute of Technology (IIT) Madras. November, 2018</dd>
     <dd>Amazon, Bangalore. October, 2018</dd>
     <dd>IBM-IRL, Bangalore. July 2018.</dd>
     
  <dt><span style="color:DarkBlue">Online Learning with Structured Losses</span></dt>   
     <dd>Conduent Labs, Bangalore. October, 2017.</dd>    
</dl>

<!-- 
<ul>
     <li><span style="color:blue">PbRL: Preference based Reinforcement Learning.</span> RL Track, Microsoft Research Summit. October 2021.</li>
     <li><span style="color:blue">Adversarial Dueling Bandits.</span> Data Science in India, KDD Conference, India. August 2021.</li>
     <li><span style="color:blue">Battle of Bandits.</span> Sabarmati Seminar Series, IIT Gandhinagar, India. July 2021.</li>
     <li><span style="color:blue">Online Learning from Preferences.</span> SIERRA-Seminar, Inria, Paris. January 2020.</li>
     <li><span style="color:blue">Structured Battling Bandits.</span> Microsoft Research, Bangalore, India. October 2019.</li>
</ul>


*3 talks at ICML*, 2021. <br/><br/>
ensp;ensp;<span style="color:blue">Active Ranking with Subset-wise Preferences.</span> *Artificial Intelligence and Statistics (AISTATS)*. Naha, Okinawa, Japan, April 2019.<br/><br/>
<span style="color:blue">PhD Thesis Overview: Information Aggregation from Preferential Feedback.</span> *EECS Symposium, Indian Institute of Science, Bangalore, India*. April 2019.<br/><br/>
<span style="color:blue">PAC Battling-Bandits in the Plackett-Luce model.</span> *Algorithmic Learning Theory (ALT), 2019*. Chicago, USA, March 2019.<br/> 
-->

