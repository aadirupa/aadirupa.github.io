---
title: ""
collection: talks
type: "Talk"
permalink: /talks/list.md
---

<h2>Tutorials:</h2>
<ul>
     <li><span style="color:blue">Preference Bandits.</span> Asian Conference of Machine Learning (ACML). November 2021.</li>
     <li><span style="color:blue">Bandits for Beginners.</span> Microsoft Reactor: Data Science and Machine Learning Track. November 2021.</li>
     <li><span style="color:blue">Short Tutorial: (1). Support Vector Machines, (2). Winnow and Perceptron Algorithms.</span> M.S. Ramaiah Institute of Technology, Bangalore, India. May 2018.</li>
     <li><span style="color:blue">Let's Tame the Bandits!</span> Undergraduate Summer School, Dept. of Computer Science and Automation (CSA), Indian Institute of Science (IISc). July 2018.</li>
</ul>

<h2>Talks:</h2>
<dl>
  <dt>Information Aggregation from Unconventional Feedback</dt>
     <dd>Oracle Research, November, 2021.</dd>
  <dt>Preference based Reinforcement Learning (PbRL)</dt>
     <dd>Microsoft Research Tri-Lab Offsite, 2021</dd>
     <dd>RL Track, Microsoft Research Summit, 2021</dd>
  <dt>Battling Bandits: Exploiting Subsetwise Preferences</dt>   
     <dd>---</dd>   
     <dd>---</dd>   
     <dd>---</dd>   
     <dd>---</dd>   
     <dd>---</dd>   
  <dt>Adversarial Dueling Bandits</dt>   
     <dd>Data Science in India, KDD Conference, India, August 2021.</dd>  
  <dt>Online Learning with Structured Losses</dt>   
     <dd>Indian Institute of Technology (IIT), Madras, India. November, 2018.</dd>   
  <dt>Bandits, Experts and Rank Aggregation</dt>   
     <dd>TCS Research Lab, Bangalore, India. June, 2018</dd>   
</dl>

<!-- 
<ul>
     <li><span style="color:blue">PbRL: Preference based Reinforcement Learning.</span> RL Track, Microsoft Research Summit. October 2021.</li>
     <li><span style="color:blue">Adversarial Dueling Bandits.</span> Data Science in India, KDD Conference, India. August 2021.</li>
     <li><span style="color:blue">Battle of Bandits.</span> Sabarmati Seminar Series, IIT Gandhinagar, India. July 2021.</li>
     <li><span style="color:blue">Online Learning from Preferences.</span> SIERRA-Seminar, Inria, Paris. January 2020.</li>
     <li><span style="color:blue">Structured Battling Bandits.</span> Microsoft Research, Bangalore, India. October 2019.</li>
</ul>


*3 talks at ICML*, 2021. <br/><br/>
ensp;ensp;<span style="color:blue">Active Ranking with Subset-wise Preferences.</span> *Artificial Intelligence and Statistics (AISTATS)*. Naha, Okinawa, Japan, April 2019.<br/><br/>
<span style="color:blue">PhD Thesis Overview: Information Aggregation from Preferential Feedback.</span> *EECS Symposium, Indian Institute of Science, Bangalore, India*. April 2019.<br/><br/>
<span style="color:blue">PAC Battling-Bandits in the Plackett-Luce model.</span> *Algorithmic Learning Theory (ALT), 2019*. Chicago, USA, March 2019.<br/> 
-->
