---
layout: archive
title: ""
permalink: /publications/
author_profile: true
---

<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">  
<style>
a:link {
  color: RoyalBlue;
  background-color: transparent;
  text-decoration: none;
}

a:visited {
  color: Purple;
  background-color: transparent;
  text-decoration: none;
}

a:hover {
  color: RoyalBlue;
  background-color: transparent;
  text-decoration: underline;
}

a:active {
  color: DarkRed;
  background-color: transparent;
  text-decoration: underline;
}
  
.collapsible {
  background-color: #777;
  color: white;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  border: none;
  text-align: left;
  outline: none;
  font-size: 15px;
}

.active, .collapsible:hover {
  background-color: #555;
}

.content {
  padding: 0 18px;
  display: none;
  overflow: hidden;
  background-color: #f1f1f1;
}
</style>  
</head>  
  
<body>
<hr style="color:black;">
  
<a href="https://aadirupa.github.io#selected_publications">[Selected Papers]</a> &nbsp;
<a href="https://aadirupa.github.io/publications#full_publications" target="_blank">[Full List]</a> &nbsp;
<a href="https://scholar.google.co.in/citations?user=7a49tQYAAAAJ&hl=en" target="_blank">[Google Scholar]</a> &nbsp;
<a href="https://dblp.org/pid/14/10003.html" target="_blank">[DBLP]</a> &nbsp;
<a href="https://arxiv.org/find/all/1/au:+saha_aadirupa/0/1/0/all/0/1" target="_blank">[arXiv]</a>  

<br> <br>
<!--  -->

<details>
<summary><span style="color:SteelBlue;" align="justify"> <font color="SteelBlue">Collaborators.</font> </span></summary>
<span class="abstract-text" style="font-size:1em; color:Black; text-align: justify">
  <p align="justify" vspace = "0px" width="160px"> Throughout my journey, I have been incredibly fortunate to work alongside some of the brilliant minds in the field, whose wisdom has been instrumental in shaping my work and enriching my knowledge fundamentally:
   <!-- <a href="https://web.stanford.edu/~asi/" target="_blank">Hilal Asi</a>, -->
   <!-- <a href="https://www.hni.uni-paderborn.de/en/ism/staff/?mitarbeiter=155385509103009" target="_blank">Viktor Bengs</a>, -->
   <a href="https://www.csa.iisc.ac.in/~chiru/" target="_blank">Chiranjib Bhattacharyya</a>,
   <a href="https://home.ttic.edu/~avrim/" target="_blank">Avrim Blum</a>, 
   <!-- <a href="https://www.ttic.edu/faculty/cohen/" target="_blank">Lee Cohen</a>, -->
   <!-- <a href="https://www.microsoft.com/en-us/research/people/sadevlin/" target="_blank">Sam Devlin</a>, -->
   <a href="https://sites.google.com/site/christosdimitrakakis" target="_blank">Christos Dimitrikakis</a>,
   <a href="https://people.ece.uw.edu/fazel_maryam/" target="_blank">Maryzam Fazel</a>,
   <!-- <a href="https://sites.google.com/view/yonathan-efroni/home" target="_blank">Yonathan Efroni</a>, -->
   <a href="http://vtaly.net/" target="_blank">Vitaly Feldman</a>
   <a href="http://pierre.gaillard.me/" target="_blank">Pierre Gaillard</a>,
   <!-- <a href="https://sites.google.com/view/suprovat/home" target="_blank">Suprovat Ghoshal</a>, -->
   <a href="https://ece.iisc.ac.in/~aditya/" target="_blank">Aditya Gopalan</a>,
   <a href="https://www.microsoft.com/en-us/research/people/kahofman/" target="_blank">Katja Hofmann</a>
   <a href="https://www.kiml.ifi.lmu.de/team/huellermeier/" target="_blank">Eyke Hüllermeier</a>,
   <a href="https://www.prateekjain.org/" target="_blank">Prateek Jain</a>,
   <!-- <a href="https://sumeetsk.github.io/" target="_blank">Sumeet Katariya</a>, -->
   <!-- <a href="https://sites.google.com/view/thomaskb" target="_blank">Thomas Kleine Buening</a>, -->
   <a href="https://tomerkoren.github.io/" target="_blank">Tomer Koren</a>,
   <a href="https://bkveton.com/" target="_blank">Branislav Kveton</a>, 
   <a href="https://people.cs.umass.edu/~akshay/" target="_blank">Akshay Krishnamurthy</a>,
   <a href="https://haipeng-luo.net/" target="_blank">Haipeng Luo</a>,
   <a href="https://webee.technion.ac.il/Sites/People/shie/" target="_blank">Shie Mannor</a>,
   <a href="https://www.tau.ac.il/~mansour/" target="_blank">Yishay Mansour</a>,
   <!-- <a href="https://sites.google.com/view/nadav-merlis/" target="_blank">Nadav Merlis</a>, -->
   <!-- <a href="https://www.microsoft.com/en-us/research/people/nagarajn/" target="_blank">Nagarajan Natarajan</a>, -->
   <a href="https://praneethnetrapalli.org/" target="_blank">Praneeth Netrapalli</a>,
   <!-- <a href="https://www.aldopacchiano.ai/" target="_blank">Aldo Pacchiano</a>, -->
   <!-- <a href="https://kishinmh.github.io/" target ="_blank">Kshitij Patel</a>, -->
   <a href="https://vianney.ai/" target ="_blank">Vianney Perchet</a>,
   <a href="https://www.schapire.net/" target="_blank">Rob Schapire</a>, 
   <!-- <a href="https://sites.google.com/view/hanshao" target="_blank">Han Shao</a>, -->
   <a href="https://nati.ttic.edu/" target="_blank">Nati Srebro</a>, 
   <a href="https://misovalko.github.io/" target="_blank">Michal Valko</a>,
   <a href="https://home.ttic.edu/~mwalter/" target="_blank">Matthew Walter</a>
   <!-- <a href="https://ttic.edu/faculty/wang/" target="_blank">Lingxiao Wang</a>, -->
   <!-- <a href="https://www.haifeng-xu.com/" target="_blank">Haifeng Xu</a> -->
  (in alphabetical order).</p>
</span>
</details> 
  
<h2 style="color:SteelBlue;" vspace="0px;"><a id="preprints">Preprints:</a></h2>
  
<ul style="margin:1;padding:1">


<li>  <b>Adaptive Bandits under Varying Source Quality</b>  <a href="" target="_blank" LINK="red"> [Arxiv: Coming Soon]</a>
<br>  Amith Bhat, Aadirupa Saha, Haipeng Luo
</li>

<li>  <b>Optimal Rates for Learning Quantum States with Linear Tomography</b> 
<br>  Aadirupa Saha, Dmitry Ostrovsky 
</li>

<li> <b>Double-Monster: Efficient Min-Max Strategy for Personalized Prediction under General Preferences.</b> 
<br>  Aadirupa Saha, Robert Schapire
</li>

<li>  <b>Efficient Predictive Models without Compromising User Privacy</b>  <a href="https://arxiv.org/abs/2403.15045" target="_blank" LINK="red"> [Arxiv version]</a>
<br>  Aadirupa Saha, Hilal Asi
</li>

<li>  <b>Learning to Allocate Resources with Censored Feedback</b>  <a href="" target="_blank" LINK="red"> [Arxiv version]</a>
<br>  Giovanni Montanari, Côme Fiegel, Aadirupa Saha, Vianney Perchet
</li>

 <li>  <b>Best Arm Identification in Linear MNL-Bandits.</b>  <a href="https://arxiv.org/abs/2104.05294" target="_blank" LINK="red"> [Arxiv Version]</a>
 <br>  Shubham Gupta, Aadirupa Saha, Sumeet Katariya
 </li>

<!-- 
<li>  <b>Optimal Rates for DCO</b>  <a href="" target="_blank" LINK="red"> [Arxiv: Coming soon!]</a>
<br> Vitaly Feldman, Aadirupa Saha
</li>

<li>  <b>Cost or Quality: Your Choice! Multi-fidelity Feedback in Sequential Decision Making Under Bandit Feedback.</b>  <a href="" target="_blank" LINK="red"> [Arxiv: Coming soon!]</a>
<br>  Chinmaya Kausik, Yonathan Efroni, Nadav Merlis, Aadirupa Saha
</li> 
-->

</ul>  
  
<h2 style="color:SteelBlue;" vspace="0px;"><a id="full_publications">Full list of Publications:</a></h2>

<h2 style="color:DarkRed;">2026</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 
<ul style="margin:1;padding:1"> 

<li>  <b>LLM-as-a-Judge on a Budget</b>  <a href="" target="_blank" LINK="red"> [Arxiv version]</a>
<br>  Aadirupa Saha, Branislav Kveton, Aniket Wagde
<br>  International Conference on Artificial Intelligence and Statistics, AIStats 2026  
</li>

<li>  <b>Stochastically Dominant Preference Optimization: Policy Improvement for All</b>  <a href="" target="_blank" LINK="red"> [Arxiv version]</a>
<br>  Ali Farajzadeh, Syed M Abbas, Aadirupa Saha, Brian D Ziebart
<br>  International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2026 (Extended Abstract)  
</li>

</ul> 

<h2 style="color:DarkRed;">2025</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 
<ul style="margin:1;padding:1"> 

<li> <b>Efficient and Near-Optimal Algorithm for General Contextual Dueling Bandits with Offline Regression Oracles</b>  <a href="https://neurips.cc/virtual/2025/loc/san-diego/poster/119046" target="_blank" LINK="red"> [NeurIPS version]</a>
<br>  Aadirupa Saha, Robert Schapire
<br>  In Neural Information Processing Systems, NeurIPS 2025 
</li>

<li> <b>Imitation Beyond Expectation Using Pluralistic Stochastic Dominance</b>  <a href="https://neurips.cc/virtual/2025/loc/san-diego/poster/117414" target="_blank" LINK="red"> [NeurIPS version]</a>
<br>  Ali Farajzadeh, Danyal Saeed, Syed M Abbas, Rushit N. Shah, Aadirupa Saha, Brian D Ziebart
<br>  In Neural Information Processing Systems, NeurIPS 2025 <span style="color:Red;"><b> (*Spotlight*)</b></span>
</li>

<li>  <b>Source Adaptive Online Learning under Heteroscedastic Noise</b>  <a href="https://opt-ml.org/papers/2025/paper162.pdf" target="_blank" LINK="red"> [OPT-ML version]</a>
<br>  Amith Bhat, Aadirupa Saha, Thomas Kleine Buening, Haipeng Luo
<br>  In OPT for ML Workshop, Neural Information Processing Systems, NeurIPS 2025       
</li>

<li>  <b>Efficient Algorithms for Combinatorial-Bandits with Monotonicity.</b>  <a href="https://openreview.net/pdf?id=D3drIoEW5B" target="_blank" LINK="red"> [OPT-ML version]</a>
<br> Aniket Wadge, Aadirupa Saha
<br>  In OPT for ML Workshop, Neural Information Processing Systems, NeurIPS 2025       
</li>

<li> <b>HPO: Provably Faster Convergence Rates by Combining Offline Preferences with Online Exploration</b>  <a href="https://arxiv.org/abs/2412.10616" target="_blank" LINK="red"> [Arxiv version] </a> <a href="https://openreview.net/pdf?id=YBBXsVta2x" target="_blank" LINK="red"> [Workshop version]</a>
<br>  Avinandan Bose, Zhihan Xiong, Aadirupa Saha, Simon Shaolei Du, Maryam Fazel
<br>  In The Next Frontier in Reliable AI Workshop, International Conference on Learning Representations (ICLR), 2025   
</li>

 <li>  <b>Tracking the Best Expert Privately</b>  <a href="https://arxiv.org/abs/2503.09889" target="_blank" LINK="red"> [Arxiv version]</a> 
 <br>  Hilal Asi, Vinod Raman, Aadirupa Saha (alphabetical)
 <br>  International Conference on Machine Learning, ICML 2025
 </li> 

  <li>  <b>Dueling Convex Optimization for General Preferences: An Unified Framework for Optimal Convergence Rates.</b>  <a href="https://arxiv.org/pdf/2210.02562.pdf" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Tomer Koren, Yishay Mansour
  <br>  International Conference on Machine Learning, ICML 2025
  </li> 
  
  <li>  <b>Stop Relying on No-Choice and Do not Repeat the Moves: Optimal, Efficient and Practical Algorithms for Assortment Optimization</b>  <a href="https://arxiv.org/abs/2402.18917" target="_blank" LINK="red"> [Arxiv version]</a>
  <br>  Aadirupa Saha, Pierre Gaillard
  <br> International Conference on Learning Representations (ICLR), 2025   
  <details>
  <summary><span style="color:Maroon;"> 1 min pitch!</span></summary>
  <span class="abstract-text" style="font-size:.90em; color:Maroon; text-align: justify">If you've ever encountered MNL Assortment Optimization problem, the go-to approach is to offer the same set of products repeatedly until your customer is really annoyed and selects no item! In fact, it requires a "belief" that no selection is their most preferred choice :-( Oh no! 
<br><br>
But why be so pessimistic? And why annoy your customers repeatedly offering the same items and hoping them to leave (i.e. they decide to choose none of the offered items!)? We got a new idea with no such issues. How? We simply found better concentration tricks! It was a long time wish to resolve this efficiently. 
  </span>
  </details>
 </li>

</ul>    

<h2 style="color:DarkRed;">2024</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 
  
<ul style="margin:1;padding:1"> 
  <li>  <b>Strategic Linear Contextual Bandits.</b>  <a href="https://arxiv.org/pdf/2406.00551" target="_blank" LINK="red"> [Arxiv version]</a>
  <br> Thomas Kleine Buening, Aadirupa Saha, Haifeng Xu, Christos Dimitrakakis
  <br> In Neural Information Processing Systems, NeurIPS 2024  
  </li>

 <li>  <b>Dueling in the Dark: An Efficient and Optimal O(&radic;T) Mirror Descent Approach for Competing against Adversarial Preferences.</b>  <a href="" target="_blank" LINK="red"> [Arxiv: Coming soon!]</a>
  <br> Aadirupa Saha, Barry-John Theobald, Yonathan Efroni
  <br> In OPT for ML Workshop, Neural Information Processing Systems, NeurIPS 2024       
 </li>

  <li><b>A Graph Theoretic Approach for Preference Learning with Feature Information.</b>  <a href=" " target="_blank" LINK="red"> [Arxiv Version]</a>
 <br>  Aadirupa Saha, Arun Rajkumar
 <br> In Uncertainty in Artificial Intelligence, UAI 2024 <span style="color:Red;"><b> (*Oral*)</b></span>
 </li>
  
   <li>  <b>Social Welfare for RecSys: Bandits Meet Mechanism Design to Combat Clickbait in Online Recommendation.</b> <a href="https://arxiv.org/abs/2311.15647" target="_blank" LINK="red"> [Arxiv version]</a>
  <br>  Thomas Kleine Buening, Aadirupa Saha, Haifeng Xu, Christos Dimitrakakis
   <br> International Conference on Learning Representations (ICLR), 2024 <span style="color:Red;"><b> (*Spotlight*)</b></span>
   </li>
  
  <li> <b>Only Pay for What Is Uncertain: Variance-Adaptive Thompson Sampling.</b> <a href="https://arxiv.org/abs/2303.09033" target="_blank" LINK="red">[Arxiv version]</a>
  <br>  Aadirupa Saha, Branislav Kveton
  <br> International Conference on Learning Representations (ICLR), 2024 
  <details>
  <summary><span style="color:Maroon;"> 1 min pitch!</span></summary>
  <span class="abstract-text" style="font-size:.90em; color:Maroon; text-align: justify">We lay the foundations for Bayesian multi-armed bandits with known and unknown heterogeneous reward variances with Thompson sampling. Our regret analysis shows improved performance with lower reward variances, implying faster learning in low-variance regimes. So why regret if you are already confident - Only Pay for What Is Uncertain!</span>
  </details>
  </li>

  <li>  <b>Efficient Private Federated Non-Convex Optimization With Shuffled Model.</b>  <a href="https://openreview.net/forum?id=t7mv0y8OPE
" target="_blank" LINK="red">[Workshop Version]</a>
  <br>  Lingxiao Wang, Xingyu Zhou, Kumar Kshitij Patel, Lawrence Tang, Aadirupa Saha
  <br>  Privacy Regulation and Protection in ML Workshop, International Conference on Learning Representations (ICLR), 2024 
 </li>
  
  <li>  <b>Think Before You Duel: Understanding Complexities of Preference Learning under Constrained Resources.</b>  <a href="https://arxiv.org/pdf/2312.17229.pdf" target="_blank" LINK="red"> [Arxiv version]</a>
  <br>  Rohan Deb, Aadirupa Saha
  <br>  International Conference on Artificial Intelligence and Statistics, AIStats 2024
 </li>

<li>  <b>On the Vulnerability of Fairness Constrained Learning to Malicious Noise.</b> <a href="https://arxiv.org/abs/2307.11892" LINK="red">[Arxiv version]</a>
  <br>  Avrim Blum, Princewill Okoroafor, Aadirupa Saha, Kevin Stangl
  <br> International Conference on Artificial Intelligence and Statistics, AIStats 2024
</li> 

<li>  <b>Faster Convergence with MultiWay Preferences.</b>  <a href="https://arxiv.org/abs/2312.11788" target="_blank" LINK="red"> [Arxiv version]</a>
  <br>  Aadirupa Saha, Vitaly Feldman, Tomer Koren, Yishay Mansour
  <br>  International Conference on Artificial Intelligence and Statistics, AIStats 2024
</li>
  
  <li> <a href="https://arxiv.org/abs/2311.11185" LINK="red">Dueling Optimization with a Monotone Adversary</a>
  <br>  Avrim Blum, Meghal Gupta, Gene Li, Naren Sarayu Manoj, Aadirupa Saha, Yuanyuan Yang
  <br> Algorithmic Learning Theory, ALT, 2024 <span style="color:Red;"><b> (*Outstanding Paper Award*)</b></span>  
 </li>
  
    
</ul>    

  
<h2 style="color:DarkRed;">2023</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 
  
<ul style="margin:1;padding:1">
  <li>  <a href="" target="_blank">Eliciting User Preferences for Personalized Multi-Objective Decision Making through Comparative Feedback</a>  <a href="https://arxiv.org/abs/2302.03805" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Han Shao, Lee Cohen, Avrim Blum, Yishay Mansour, Aadirupa Saha, Mathew Walter
  <br>  In Neural Information Processing Systems, NeurIPS 2023
  </li>
  
  <li>  <b>Dueling Optimization with a Monotone Adversary.</b> <a href="https://arxiv.org/abs/2311.11185" LINK="red">[Arxiv version]</a>
  <br>  Avrim Blum, Meghal Gupta, Gene Li, Naren Sarayu Manoj, Aadirupa Saha, Yuanyuan Yang
  <br> NeurIPS OPT+ML Workshop, NeurIPS, 2023 <em>(Oral)</em>
 </li>
  
  <li>  <b>On the Vulnerability of Fairness Constrained Learning to Malicious Noise.</b> <a href="https://arxiv.org/abs/2307.11892" LINK="red">[Arxiv version]</a>
  <br>  Avrim Blum, Princewill Okoroafor, Aadirupa Saha, Kevin Stangl
  <br> Algorithmic Fairness through the Lens of Time Workshop, NeurIPS, 2023
  </li> 

  <li>  <a href="https://proceedings.mlr.press/v202/patel23a.html" target="_blank">Federated Online and Bandit Convex Optimization</a> <a href="https://arxiv.org/abs/2311.17586" target="_blank" LINK="red"> [Arxiv Version]</a> 
  <br>  Kumar Kshitij Patel, Lingxiao Wang, Aadirupa Saha, Nati Srebro
  <br>  In International Conference on Machine Learning, ICML 2023
  </li>   

  <li>  <a href="https://openreview.net/pdf?id=iIhXNqNh1c" target="_blank" LINK="red">Bandits Meet Mechanism Design
to Combat Clickbait in Online Recommendation</a>  <a href="https://arxiv.org/abs/2311.15647" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Thomas Kleine Buening, Aadirupa Saha, Haifeng Xu, Christos Dimitrakakis
  <br>  Interactive Learning with Implicit Human Feedback Workshop, ICML 2023</li>
  
  <li>  <a href="https://proceedings.mlr.press/v206/gaillard23a.html" target="_blank">One Arrow, Two Kills: An Unified Framework for Achieving Optimal Regret Guarantees in Sleeping Bandits</a>   <a href="https://arxiv.org/abs/2210.14998" target="_blank" LINK="red"> [Arxiv Version]</a><a href="https://www.youtube.com/watch?v=m1qQe3lGXWI" target="_blank" LINK="red"> [Talk]</a>
  <br>  Pierre Gaillard, Aadirupa Saha, Soham Dan
  <br>  In International Conference on Artificial Intelligence and Statistics, AIStats 2023</li>  
  <details>
  <summary><span style="color:Maroon;"> 1 min pitch!</span></summary>
  <span class="abstract-text" style="font-size:.90em; color:Maroon; text-align: justify">Sleeping Bandits are as interesting as they sound, but what is the right measure of Sleeping Regret? So many different notions of regrets were studied in the literature --- Sleeping External regret, Ordering regret, Policy regret --- but it is confusing to keep track of the implications of so many different notions, i.e. every combination of stochastic or adversarial losses and availability pairs.
    <br><br>
    Can we unify them under a single measure? We found one in this work - Sleeping Internal Regret! One of our main contributions is unifying existing notions of regret in sleeping bandits and exploring their implications for each other. 
    <br><br>
    Our proposed algorithm achieves sublinear Internal Regret, even when losses and availabilities are both adversarial, which is the hardest combination of sleeping setup! Further, our results show how a low internal regret leads to both low external regret and low policy regret - One arrow, Two Kills! 
    <br><br>
    Our unified notion of sleeping regret also helps to invent a general notion of Sleeping Dueling Bandits that is stronger than the existing regret definitions used in the contemporary dueling bandits literature and overcomes the issue of repeated draws if needed. This is the first bound of this kind in the dueling literature with many potentials!</span>
  </details>
  
  <li>  <a href="https://proceedings.mlr.press/v206/kleine-buening23a/kleine-buening23a.pdf" target="_blank">ANACONDA: Improved Dynamic Regret Algorithm for Adaptive Non-Stationary Dueling Bandits</a>   <a href="https://arxiv.org/pdf/2210.14322.pdf" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Thomas Kleine Buening, Aadirupa Saha
  <br>  In International Conference on Artificial Intelligence and Statistics, AIStats 2023</li>                     
  
  <li>  <a href="https://proceedings.mlr.press/v206/saha23a/saha23a.pdf" target="_blank">Dueling RL: Reinforcement Learning with Trajectory Preferences</a>  <a href="https://arxiv.org/abs/2111.04850" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br> Aadirupa Saha*,  Aldo Pacchiano*, Jonathan Lee (*Equal contribution)
  <br>  In International Conference on Artificial Intelligence and Statistics, AIStats 2023</li>                     
    
</ul>    
  
<h2 style="color:DarkRed;">2022</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 
  
<ul style="margin:1;padding:1">
  
  <li>  <a href="https://kishinmh.github.io/FEDOSGD.pdf" target="_blank"> Distributed Online and Bandit Convex Optimization</a>
  <br>  Kumar Kshitij Patel, Aadirupa Saha, Lingxiao Wang, Nati Srebro
  <br>  In OPT ML Workshop, Neural Information Processing Systems, NeurIPS 2022</li>                     
  
  <li>  <a href ="https://proceedings.mlr.press/v162/saha22a.html"> Versatile Dueling Bandits: Best-of-both-World Analyses for Online Learning from Preferences.</a>  <a href="http://arxiv.org/abs/2202.06694" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Pierre Gaillard
  <br>  In International Conference on Machine Learning, ICML 2022</li>
  
  <li>  <a href ="https://proceedings.mlr.press/v162/saha22b.html"> Optimal and Efficient Dynamic Regret Algorithms for Non-Stationary Dueling Bandits.</a>  <a href="https://arxiv.org/abs/2111.03917" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Aadirupa Saha*, Shubham Gupta* (*Equal contribution)
  <br>  In International Conference on Machine Learning, ICML 2022</li>
  
  <li>  <a href="https://proceedings.mlr.press/v162/bengs22a/bengs22a.pdf"> Stochastic Contextual Dueling Bandits under Linear Stochastic Transitivity Models.</a>  <a href="https://arxiv.org/abs/2202.04593" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Viktor Bengs, Aadirupa Saha, Eyke Hüllermeier 
  <br>  In International Conference on Machine Learning, ICML 2022</li>
  
  <li>  <a href="https://proceedings.mlr.press/v167/saha22a/saha22a.pdf"> Efficient and Optimal Algorithms for Contextual Dueling Bandits under Realizability</a>  <a href="https://arxiv.org/abs/2111.12306" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Akshay Krishnamurthy
  <br>  In Algorithmic Learning Theory, ALT 2022</li>  
  
  <li>  <a href="https://proceedings.mlr.press/v151/saha22a/saha22a.pdf"> Exploiting Correlation to Achieve Faster Learning Rates in Low-Rank Preference Bandits</a> <a href=""> [Arxiv Version]</a>
  <br> Aadirupa Saha*, Suprovat Ghoshal* (*Equal contribution)
  <br> In International Conference on Artificial Intelligence and Statistics, AIStats 2022</li>  
    
</ul>    
  
  
<h2 style="color:DarkRed;">2021</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 
  
<ul style="margin:1;padding:1">
  <li>  <a href="https://proceedings.neurips.cc/paper/2021/file/e97ee2054defb209c35fe4dc94599061-Supplemental.pdf" target="_blank"> Dueling Bandits with Adversarial Sleeping</a> <a href="https://arxiv.org/abs/2107.02274" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Pierre Gaillard
  <br>  In Neural Information Processing Systems, NeurIPS 2021</li>

  <li>  <a href="https://proceedings.neurips.cc/paper/2021/file/fc3cf452d3da8402bebb765225ce8c0e-Supplemental.pdf" target="_blank">Optimal Algorithms for Stochastic Contextual Dueling Bandits</a> 
  <br>  Aadirupa Saha
  <br>  In Neural Information Processing Systems, NeurIPS 2021</li>
  
  <li>  <a href="http://proceedings.mlr.press/v139/saha21b.html" target="_blank">Dueling Convex Optimization</a>
  <br>  Aadirupa Saha, Tomer Koren, Yishay Mansour
  <br>  In International Conference on Machine Learning, ICML 2021</li>
  
  <li>  <a href="http://proceedings.mlr.press/v139/saha21a.html" target="_blank">Adversarial Dueling Bandits</a> <a href="https://arxiv.org/abs/2010.14563" target="_blank"> [Arxiv Version]</a>
 <br>  Aadirupa Saha, Tomer Koren, Yishay Mansour
  <br>  In International Conference on Machine Learning, ICML 2021</li>
    
  <li> <a href="http://proceedings.mlr.press/v139/saha21c.html" target="_blank">Optimal Regret Algorithm for Pseudo-1d Bandit Convex Optimization</a> <a href="https://arxiv.org/abs/2102.07387" target="_blank"> [Arxiv Version]</a>
  <br> Aadirupa Saha, Nagarajan Natarajan, Praneeth Netrapalli, Prateek Jain
  <br> In International Conference on Machine Learning, ICML 2021</li>

  <li> <a href="https://proceedings.mlr.press/v139/efroni21a.html" target="_blank">Confidence-Budget Matching for Sequential Budgeted Learning</a> <a href="https://arxiv.org/abs/2102.03400" target="_blank"> [Arxiv Version]</a>
  <br> Yonathan Efroni, Nadav Merlis, Aadirupa Saha, Shie Mannor
  <br> In International Conference on Machine Learning, ICML 2021</li>
  
   <li> <a href="https://proceedings.mlr.press/v161/loftin21a/loftin21a.pdf" target="_blank">Strategically Efficient Exploration in Competitive Multi-agent Reinforcement Learning</a> <a href="https://arxiv.org/abs/2107.14698" target="_blank"> [Arxiv Version]</a>
  <br> Robert Loftin, Aadirupa Saha, Sam Devlin, Katja Hofmann
  <br> In Uncertainty in Artificial Intelligence, UAI 2021</li>

</ul> 
  
<h2 style="color:DarkRed;">2020</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 
  
<ul style="margin:1;padding:1">
  
  <li>  <a href="https://proceedings.mlr.press/v119/saha20b.html" target="_blank" LINK="red">From PAC to Instance-Optimal Sample Complexity in the Plackett-Luce Model</a> <a href="https://arxiv.org/abs/1903.00558" target="_blank"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Aditya Gopalan
  <br>  In International Conference on Machine Learning, ICML 2020</li>
  
  <li>  <a href="https://proceedings.mlr.press/v119/saha20a" target="_blank" LINK="red">Improved Sleeping Bandits with Stochastic Action Sets and Adversarial Rewards</a> <a href="https://arxiv.org/abs/2004.06248" target="_blank"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Pierre Gaillard, Michal Valko
  <br>  In International Conference on Machine Learning, ICML 2020</li>
    
  <li>  <a href="https://proceedings.mlr.press/v108/aadirupa-saha20a.html" target="_blank">Best-item Learning in Random Utility Models with Subset Choices</a> <a href="https://arxiv.org/abs/2002.07994" target="_blank"> [Arxiv Version]</a>
  <br> Aadirupa Saha, Aditya Gopalan
  <br>  In International Conference on Artificial Intelligence and Statistics, AIStats 2020</li>  
  
  <li>  <a href="http://proceedings.mlr.press/v129/saha20a.html" target="_blank" LINK="red">Polytime Decomposition of Generalized Submodular Base Polytopes with Efficient Sampling</a>
  <br>  Aadirupa Saha
  <br>  In Asian Conference on Machine Learning, ACML 2020</li>
</ul>  
  
<h2 style="color:DarkRed;">2019</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 
  
<ul style="margin:1;padding:1">
   <li>  <a href="http://papers.nips.cc/paper/8384-combinatorial-bandits-with-relative-feedback" target="_blank">Combinatorial Bandits with Relative Feedback</a><a href="https://arxiv.org/abs/1903.00543" target="_blank"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Aditya Gopalan
  <br>  In Neural Information Processing Systems, NeurIPS 2019</li>
  
  <li> <a href="http://proceedings.mlr.press/v115/s20a.html" target="_blank">Be Greedy: How Chromatic Number meets Regret Minimization in Graph Bandits</a>
  <br> Shreyas Seshadri*, Aadirupa Saha*, Chiranjib Bhattacharyya (*Equal Contribution)
  <br> In Uncertainty in Artificial Intelligence, UAI 2019</li>
    
  <li>  <a href="https://proceedings.mlr.press/v89/saha19a" target="_blank">Active Ranking with Subset-wise Preferences</a> <a href="https://arxiv.org/abs/1810.10321" target="_blank"> [Arxiv Version]</a>
  <br> Aadirupa Saha, Aditya Gopalan
  <br>  In International Conference on Artificial Intelligence and Statistics, AIStats 2019</li>  
  
  <li>  <a href="http://proceedings.mlr.press/v98/saha19a.html" target="_blank">PAC Battling Bandits in the Plackett-Luce Model</a> <a href="https://arxiv.org/abs/1808.04008" target="_blank"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Aditya Gopalan
  <br>  In Algorithmic Learning Theory, ALT 2019</li>  
  
  <li>  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5182" target="_blank">How Many Pairwise Preferences Do We Need to Rank A Graph Consistently?</a> <a href="https://arxiv.org/abs/1811.02161" target="_blank"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Rakesh Shivanna, Chiranjib Bhattacharyya
  <br>  In AAAI Conference on Artificial Intelligence, AAAI 2019</li>  
</ul>  
    
<h2 style="color:DarkRed;">2018</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 

<ul style="margin:1;padding:1">
  <li>  <a href="http://auai.org/uai2018/proceedings/papers/290.pdf" target="_blank">Battle of Bandits</a> 
  <br>  Aadirupa Saha, Aditya Gopalan
  <br> In Uncertainty in Artificial Intelligence, UAI 2018</li>
  
  <li>  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/11669" target="_blank">Online Learning for Structured Loss Spaces</a> <a href="https://arxiv.org/abs/1706.04125" target="_blank"> [Arxiv Version]</a>
  <br>  Siddharth Barman, Aditya Gopalan, Aadirupa Saha (Alphabetical Order)
  <br>  In AAAI Conference on Artificial Intelligence, AAAI 2018</li>  
</ul>  
  
<h2 style="color:DarkRed;">2015</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" />  

<ul style="margin:1;padding:1">
  <li>  <a href="http://proceedings.mlr.press/v37/narasimhanb15.pdf" target="_blank" LINK="red">Consistent Multiclass Algorithms for Complex Performance Measures</a>
  <br>  Harikrishna Narasimhan, Harish Ramaswamy, Aadirupa Saha, Shivani Agarwal
  <br>  In International Conference on Machine Learning, ICML 2015</li>
</ul>  
    
<h2 style="color:DarkRed;">2014</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" />   
  
<ul style="margin:1;padding:1">
  <li>  <a href="https://ieeexplore.ieee.org/document/7033097" target="_blank" LINK="red">Learning Score Systems for Patient Mortality Prediction in Intensive Care Units via Orthogonal Matching Pursuit</a> 
  <br>  Aadirupa Saha, Chandrahas Dewangan, Harikrishna Narasimhan, Sriram Sampath, Shivani Agarwal
  <br>  In International Conference on Machine Learning and Applications, ICMLA 2014</li>
</ul>  
  
<h2 style="color:DarkRed;">2013</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" />   
  
<ul style="margin:1;padding:1">
  <li>  <a href="https://link.springer.com/chapter/10.1007/978-3-642-39693-9_9" target="_blank" LINK="red">Energy Saving Replay Attack Prevention in Clustered Wireless Sensor Networks</a> 
  <br>  Amrita Ghosal, Aadirupa Saha, Sipra Das Bit
  <br>  In Pacific-Asia Workshop on Intelligence and Security Informatics, PAISI 2013</li>
</ul>  
  
<h2 style="color:DarkRed;">2011</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" />   
  
<ul style="margin:1;padding:1">
  <li>  <a href="https://link.springer.com/chapter/10.1007/978-3-642-23641-9_34" target="_blank" LINK="red">Energy-Balancing and Lifetime Enhancement of Wireless
Sensor Network with Archimedes Spiral</a> 
  <br>  Subir Halder, Amrita Ghosal, Aadirupa Saha, Sipra DasBit
  <br>  In International Conference on Ubiquitous Intelligence and Computing, ICUIC 2011</li>
</ul>    
    
<hr style="color:black;">

&nbsp;&nbsp;
<a href="https://aadirupa.github.io/publications#full_publications">[Back to Top]</a> &nbsp;
<a href="https://aadirupa.github.io#selected_publications">[Selected Papers]</a> &nbsp; 
<a href="https://aadirupa.github.io/publications#full_publications" target="_blank">[Full List]</a> &nbsp;
<a href="https://scholar.google.co.in/citations?user=7a49tQYAAAAJ&hl=en" target="_blank">[Google Scholar]</a> &nbsp;
<a href="https://dblp.org/pid/14/10003.html" target="_blank">[DBLP]</a> &nbsp;
<a href="https://arxiv.org/find/all/1/au:+saha_aadirupa/0/1/0/all/0/1" target="_blank">[arXiv]</a>   

</body>
</html>
