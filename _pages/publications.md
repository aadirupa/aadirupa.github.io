---
layout: archive
title: ""
permalink: /publications/
author_profile: true
---

<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">  
<style>
a:link {
  color: RoyalBlue;
  background-color: transparent;
  text-decoration: none;
}

a:visited {
  color: Purple;
  background-color: transparent;
  text-decoration: none;
}

a:hover {
  color: RoyalBlue;
  background-color: transparent;
  text-decoration: underline;
}

a:active {
  color: DarkRed;
  background-color: transparent;
  text-decoration: underline;
}
  
.collapsible {
  background-color: #777;
  color: white;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  border: none;
  text-align: left;
  outline: none;
  font-size: 15px;
}

.active, .collapsible:hover {
  background-color: #555;
}

.content {
  padding: 0 18px;
  display: none;
  overflow: hidden;
  background-color: #f1f1f1;
}
</style>  
</head>  
  
<body>
<a href="https://aadirupa.github.io#selected_publications">[Selected Papers]</a> &nbsp;
<a href="https://aadirupa.github.io/publications#full_publications" target="_blank">[Full List]</a> &nbsp;
<a href="https://scholar.google.co.in/citations?user=7a49tQYAAAAJ&hl=en" target="_blank">[Google Scholar]</a> &nbsp;
<a href="https://dblp.org/pid/14/10003.html" target="_blank">[DBLP]</a> &nbsp;
<a href="https://arxiv.org/find/all/1/au:+saha_aadirupa/0/1/0/all/0/1" target="_blank">[arXiv]</a>  

<!--  
<p>Test:</p>
<button type="button" class="collapsible">Open Collapsible</button>
<div class="content">
  <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.</p>
</div>
-->  

<hr style="color:black;"> 
<p align="justify" vspace = "0px" width="160px"><font color="SteelBlue">Collaborators.</font> Throughout my journey, I have been extremely fortunate to be able to work with some of the amazing research minds: 
   <a href="https://web.stanford.edu/~asi/" target="_blank">Hilal Asi</a>,
   <!--<a href="https://arindam.cs.illinois.edu/" target="_blank">Arindam Banerjee</a>,-->
   <a href="https://www.hni.uni-paderborn.de/en/ism/staff/?mitarbeiter=155385509103009" target="_blank">Viktor Bengs</a>,
   <a href="https://www.csa.iisc.ac.in/~chiru/" target="_blank">Chiranjib Bhattacharyya</a>,
   <a href="https://home.ttic.edu/~avrim/" target="_blank">Avrim Blum</a>, 
   <a href="https://www.ttic.edu/faculty/cohen/" target="_blank">Lee Cohen</a>, 
   <a href="https://www.microsoft.com/en-us/research/people/sadevlin/" target="_blank">Sam Devlin</a>, 
   <a href="https://sites.google.com/view/yonathan-efroni/home" target="_blank">Yonathan Efroni</a>,
   <a href="http://vtaly.net/" target="_blank">Vitaly Feldman</a>
   <a href="http://pierre.gaillard.me/" target="_blank">Pierre Gaillard</a>,
   <a href="https://sites.google.com/view/suprovat/home" target="_blank">Suprovat Ghoshal</a>,
   <a href="https://ece.iisc.ac.in/~aditya/" target="_blank">Aditya Gopalan</a>,
   <a href="https://www.microsoft.com/en-us/research/people/kahofman/" target="_blank">Katja Hofmann</a>,
   <a href="https://www.kiml.ifi.lmu.de/team/huellermeier/" target="_blank">Eyke Hüllermeier</a>,
   <a href="https://www.prateekjain.org/" target="_blank">Prateek Jain</a>,
   <a href="https://sumeetsk.github.io/" target="_blank">Sumeet Katariya</a>,
   <a href="https://sites.google.com/view/thomaskb" target="_blank">Thomas Kleine Buening</a>, 
   <a href="https://tomerkoren.github.io/" target="_blank">Tomer Koren</a>,
   <a href="https://bkveton.com/" target="_blank">Branislav Kveton</a>, 
   <a href="https://people.cs.umass.edu/~akshay/" target="_blank">Akshay Krishnamurthy</a>,
   <a href="https://webee.technion.ac.il/Sites/People/shie/" target="_blank">Shie Mannor</a>,
   <a href="https://www.tau.ac.il/~mansour/" target="_blank">Yishay Mansour</a>,
   <a href="https://sites.google.com/view/nadav-merlis/" target="_blank">Nadav Merlis</a>,
   <a href="https://www.microsoft.com/en-us/research/people/nagarajn/" target="_blank">Nagarajan Natarajan</a>,
   <a href="https://praneethnetrapalli.org/" target="_blank">Praneeth Netrapalli</a>,
   <a href="https://www.aldopacchiano.ai/" target="_blank">Aldo Pacchiano</a>,
   <a href="https://kishinmh.github.io/" target ="_blank">Kshitij Patel</a>, 
   <a href="https://sites.google.com/view/hanshao" target="_blank">Han Shao</a>, 
   <a href="https://nati.ttic.edu/" target="_blank">Nati Srebro</a>, 
   <a href="https://misovalko.github.io/" target="_blank">Michal Valko</a>,
   <a href="https://home.ttic.edu/~mwalter/" target="_blank">Matthew Walter</a>,
   <a href="https://ttic.edu/faculty/wang/" target="_blank">Lingxiao Wang</a>, 
   <a href="https://www.haifeng-xu.com/" target="_blank">Haifeng Xu</a>
  (in alphabetical order).</p> 
  
<h2 style="color:SteelBlue;" vspace="0px;"><a id="preprints">Preprints:</a></h2>
  
<ul style="margin:1;padding:1">

<!--
 <li>  <b>A First Step to Contextual Dueling Bandits with Offline Oracles.</b>  <a href="" target="_blank" LINK="red"> [Arxiv: Coming soon!]</a>
  <br>  Aadirupa Saha
 </li>
-->
  
  <li>  <b>Don’t Show Me the Same Movies on Repeat! Let the Bandits Battle Efficiently.</b>  <a href="" target="_blank" LINK="red"> [Arxiv: Coming soon!]</a>
  <br>  Aadirupa Saha, Pierre Gaillard
 </li>

 <li>  <b>Efficient Predictive Models without Compromising User Privacy</b>  <a href="" target="_blank" LINK="red"> [Arxiv: Coming soon!]</a>
  <br>  Aadirupa Saha, Hilal Asi
 </li>

 <li>  <b>Think Before You Duel: Understanding Complexities of Preference Learning under Constrained Resources.</b>  <a href="" target="_blank" LINK="red"> [Arxiv: Coming soon!]</a>
  <br>  Rohan Deb, Aadirupa Saha, Arindam Banerjee
 </li>
  
 <li>  <b>Preference PowerUp: Faster Convergence with MultiWay Preferences.</b>  <a href="" target="_blank" LINK="red"> [Arxiv: Coming soon!]</a>
  <br>  Aadirupa Saha, Vitaly Feldman, Tomer Koren, Yishay Mansour
 </li>

  <li>  <b>Only Pay for What Is Uncertain: Variance-Adaptive Thompson Sampling.</b> <a href="https://arxiv.org/abs/2303.09033" target="_blank" LINK="red">[Arxiv version]</a>
  <br>  Aadirupa Saha, Branislav Kveton
  <details>
  <summary><span style="color:Maroon;"> 1 min pitch!</span></summary>
  <span class="abstract-text" style="font-size:.90em; color:Maroon; text-align: justify">We lay the foundations for Bayesian multi-armed bandits with known and unknown heterogeneous reward variances with Thompson sampling. Our regret analysis shows improved performance with lower reward variances, implying faster learning in low-variance regimes. So why regret if you are already confident - Only Pay for What Is Uncertain!</span>
  </details>
  </li>
  
  <li>  <b>Social Welfare for Recommender Systems</b> <a href="https://arxiv.org/abs/2311.15647" target="_blank" LINK="red"> [Arxiv version]</a>
  <br>  Thomas Kleine Buening, Aadirupa Saha, Haifeng Xu, Christos Dimitrakakis</li>
  
  <li>  <b>Dueling Convex Optimization for General Preferences: An Unified Framework for Optimal Convergence Rates.</b>  <a href="https://arxiv.org/pdf/2210.02562.pdf" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Tomer Koren, Yishay Mansour</li>
 
  <li>  <b>Best Arm Identification in Linear MNL-Bandits.</b>  <a href="https://arxiv.org/abs/2104.05294" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Shubham Gupta, Aadirupa Saha, Sumeet Katariya</li>
  
 <!-- <li>  <b>Ranking from Pairwise Comparisons with Features: Algorithm and Graph Theoretic Analysis.</b>  <a href="https://arxiv.org/abs/1808.03857" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Arun Rajkumar</li>
  -->    
</ul>  
  
<h2 style="color:SteelBlue;" vspace="-60px;"><a id="full_publications">Full list of Publications:</a></h2>
  
<h2 style="color:DarkRed;">2023</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 
  
<ul style="margin:1;padding:1">
  <li>  <a href="" target="_blank">Eliciting User Preferences for Personalized Multi-Objective Decision Making through Comparative Feedback</a>  <a href="https://arxiv.org/abs/2302.03805" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Han Shao, Lee Cohen, Avrim Blum, Yishay Mansour, Aadirupa Saha, Mathew Walter
  <br>  In Neural Information Processing Systems, NeurIPS 2023
  </li>
  
  <li>  <b>Dueling Optimization with a Monotone Adversary.</b> <a href="https://arxiv.org/abs/2311.11185" LINK="red">[Arxiv version]</a>
  <br>  Avrim Blum, Meghal Gupta, Gene Li, Naren Sarayu Manoj, Aadirupa Saha, Yuanyuan Yang
  <br> NeurIPS OPT+ML Workshop, NeurIPS, 2023 <em>(Oral)</em>
 </li>
  
  <li>  <b>On the Vulnerability of Fairness Constrained Learning to Malicious Noise.</b> <a href="https://arxiv.org/abs/2307.11892" LINK="red">[Arxiv version]</a>
  <br>  Avrim Blum, Princewill Okoroafor, Aadirupa Saha, Kevin Stangl
  <br> Algorithmic Fairness through the Lens of Time Workshop, NeurIPS, 2023
  </li> 

  <li>  <a href="https://proceedings.mlr.press/v202/patel23a.html" target="_blank">Federated Online and Bandit Convex Optimization</a> <a href="https://arxiv.org/abs/2311.17586" target="_blank" LINK="red"> [Arxiv Version]</a> 
  <br>  Kumar Kshitij Patel, Lingxiao Wang, Aadirupa Saha, Nati Srebro
  <br>  In International Conference on Machine Learning, ICML 2023
  </li>   

  <li>  <a href="https://openreview.net/pdf?id=iIhXNqNh1c" target="_blank" LINK="red">Bandits Meet Mechanism Design
to Combat Clickbait in Online Recommendation</a>  <a href="https://arxiv.org/abs/2311.15647" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Thomas Kleine Buening, Aadirupa Saha, Haifeng Xu, Christos Dimitrakakis
  <br>  Interactive Learning with Implicit Human Feedback Workshop, ICML 2023</li>
  
  <li>  <a href="https://proceedings.mlr.press/v206/gaillard23a.html" target="_blank">One Arrow, Two Kills: An Unified Framework for Achieving Optimal Regret Guarantees in Sleeping Bandits</a>   <a href="https://arxiv.org/abs/2210.14998" target="_blank" LINK="red"> [Arxiv Version]</a><a href="https://www.youtube.com/watch?v=m1qQe3lGXWI" target="_blank" LINK="red"> [Talk]</a>
  <br>  Pierre Gaillard, Aadirupa Saha, Soham Dan
  <br>  In International Conference on Artificial Intelligence and Statistics, AIStats 2023</li>  
  <details>
  <summary><span style="color:Maroon;"> 1 min pitch!</span></summary>
  <span class="abstract-text" style="font-size:.90em; color:Maroon; text-align: justify">Sleeping Bandits are as interesting as they sound, but what is the right measure of Sleeping Regret? So many different notions of regrets were studied in the literature --- Sleeping External regret, Ordering regret, Policy regret --- but it is confusing to keep track of the implications of so many different notions, i.e. every combination of stochastic or adversarial losses and availability pairs.
    <br><br>
    Can we unify them under a single measure? We found one in this work - Sleeping Internal Regret! One of our main contributions is unifying existing notions of regret in sleeping bandits and exploring their implications for each other. 
    <br><br>
    Our proposed algorithm achieves sublinear Internal Regret, even when losses and availabilities are both adversarial, which is the hardest combination of sleeping setup! Further, our results show how a low internal regret leads to both low external regret and low policy regret - One arrow, Two Kills! 
    <br><br>
    Our unified notion of sleeping regret also helps to invent a general notion of Sleeping Dueling Bandits that is stronger than the existing regret definitions used in the contemporary dueling bandits literature and overcomes the issue of repeated draws if needed. This is the first bound of this kind in the dueling literature with many potentials!</span>
  </details>
  
  <li>  <a href="https://proceedings.mlr.press/v206/kleine-buening23a/kleine-buening23a.pdf" target="_blank">ANACONDA: Improved Dynamic Regret Algorithm for Adaptive Non-Stationary Dueling Bandits</a>   <a href="https://arxiv.org/pdf/2210.14322.pdf" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Thomas Kleine Buening, Aadirupa Saha
  <br>  In International Conference on Artificial Intelligence and Statistics, AIStats 2023</li>                     
  
  <li>  <a href="https://proceedings.mlr.press/v206/saha23a/saha23a.pdf" target="_blank">Dueling RL: Reinforcement Learning with Trajectory Preferences</a>  <a href="https://arxiv.org/abs/2111.04850" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br> Aadirupa Saha*,  Aldo Pacchiano*, Jonathan Lee (*Equal contribution)
  <br>  In International Conference on Artificial Intelligence and Statistics, AIStats 2023</li>                     
    
</ul>    
  
<h2 style="color:DarkRed;">2022</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 
  
<ul style="margin:1;padding:1">
  
  <li>  <a href="https://kishinmh.github.io/FEDOSGD.pdf" target="_blank"> Distributed Online and Bandit Convex Optimization</a>
  <br>  Kumar Kshitij Patel, Aadirupa Saha, Lingxiao Wang, Nati Srebro
  <br>  In OPT ML Workshop, Neural Information Processing Systems, NeurIPS 2022</li>                     
  
  <li>  <a href ="https://proceedings.mlr.press/v162/saha22a.html"> Versatile Dueling Bandits: Best-of-both-World Analyses for Online Learning from Preferences.</a>  <a href="http://arxiv.org/abs/2202.06694" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Pierre Gaillard
  <br>  In International Conference on Machine Learning, ICML 2022</li>
  
  <li>  <a href ="https://proceedings.mlr.press/v162/saha22b.html"> Optimal and Efficient Dynamic Regret Algorithms for Non-Stationary Dueling Bandits.</a>  <a href="https://arxiv.org/abs/2111.03917" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Aadirupa Saha*, Shubham Gupta* (*Equal contribution)
  <br>  In International Conference on Machine Learning, ICML 2022</li>
  
  <li>  <a href="https://proceedings.mlr.press/v162/bengs22a/bengs22a.pdf"> Stochastic Contextual Dueling Bandits under Linear Stochastic Transitivity Models.</a>  <a href="https://arxiv.org/abs/2202.04593" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Viktor Bengs, Aadirupa Saha, Eyke Hüllermeier 
  <br>  In International Conference on Machine Learning, ICML 2022</li>
  
  <li>  <a href="https://proceedings.neurips.cc/paper/2021/file/fc3cf452d3da8402bebb765225ce8c0e-Paper.pdf"> Efficient and Optimal Algorithms for Contextual Dueling Bandits under Realizability</a>  <a href="https://arxiv.org/abs/2111.12306" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Akshay Krishnamurthy
  <br>  In Algorithmic Learning Theory, ALT 2022</li>  
  
  <li>  <a href="https://proceedings.mlr.press/v151/saha22a/saha22a.pdf"> Exploiting Correlation to Achieve Faster Learning Rates in Low-Rank Preference Bandits</a> <a href=""> [Arxiv Version]</a>
  <br> Aadirupa Saha*, Suprovat Ghoshal* (*Equal contribution)
  <br> In International Conference on Artificial Intelligence and Statistics, AIStats 2022</li>  
    
</ul>    
  
  
<h2 style="color:DarkRed;">2021</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 
  
<ul style="margin:1;padding:1">
  <li>  <a href="https://proceedings.neurips.cc/paper/2021/file/e97ee2054defb209c35fe4dc94599061-Supplemental.pdf" target="_blank"> Dueling Bandits with Adversarial Sleeping</a> <a href="https://arxiv.org/abs/2107.02274" target="_blank" LINK="red"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Pierre Gaillard
  <br>  In Neural Information Processing Systems, NeurIPS 2021</li>

  <li>  <a href="https://proceedings.neurips.cc/paper/2021/file/fc3cf452d3da8402bebb765225ce8c0e-Supplemental.pdf" target="_blank">Optimal Algorithms for Stochastic Contextual Dueling Bandits</a> 
  <br>  Aadirupa Saha
  <br>  In Neural Information Processing Systems, NeurIPS 2021</li>
  
  <li>  <a href="http://proceedings.mlr.press/v139/saha21b.html" target="_blank">Dueling Convex Optimization</a>
  <br>  Aadirupa Saha, Tomer Koren, Yishay Mansour
  <br>  In International Conference on Machine Learning, ICML 2021</li>
  
  <li>  <a href="http://proceedings.mlr.press/v139/saha21a.html" target="_blank">Adversarial Dueling Bandits</a> <a href="https://arxiv.org/abs/2010.14563" target="_blank"> [Arxiv Version]</a>
 <br>  Aadirupa Saha, Tomer Koren, Yishay Mansour
  <br>  In International Conference on Machine Learning, ICML 2021</li>
    
  <li> <a href="http://proceedings.mlr.press/v139/saha21c.html" target="_blank">Optimal Regret Algorithm for Pseudo-1d Bandit Convex Optimization</a> <a href="https://arxiv.org/abs/2102.07387" target="_blank"> [Arxiv Version]</a>
  <br> Aadirupa Saha, Nagarajan Natarajan, Praneeth Netrapalli, Prateek Jain
  <br> In International Conference on Machine Learning, ICML 2021</li>

  <li> <a href="https://proceedings.mlr.press/v139/efroni21a.html" target="_blank">Confidence-Budget Matching for Sequential Budgeted Learning</a> <a href="https://arxiv.org/abs/2102.03400" target="_blank"> [Arxiv Version]</a>
  <br> Yonathan Efroni, Nadav Merlis, Aadirupa Saha, Shie Mannor
  <br> In International Conference on Machine Learning, ICML 2021</li>
  
   <li> <a href="https://proceedings.mlr.press/v161/loftin21a/loftin21a.pdf" target="_blank">Strategically Efficient Exploration in Competitive Multi-agent Reinforcement Learning</a> <a href="https://arxiv.org/abs/2107.14698" target="_blank"> [Arxiv Version]</a>
  <br> Robert Loftin, Aadirupa Saha, Sam Devlin, Katja Hofmann
  <br> In Uncertainty in Artificial Intelligence, UAI 2021</li>

</ul> 
  
<h2 style="color:DarkRed;">2020</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 
  
<ul style="margin:1;padding:1">
  
  <li>  <a href="https://proceedings.mlr.press/v119/saha20b.html" target="_blank" LINK="red">From PAC to Instance-Optimal Sample Complexity in the Plackett-Luce Model</a> <a href="https://arxiv.org/abs/1903.00558" target="_blank"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Aditya Gopalan
  <br>  In International Conference on Machine Learning, ICML 2020</li>
  
  <li>  <a href="https://proceedings.mlr.press/v119/saha20a" target="_blank" LINK="red">Improved Sleeping Bandits with Stochastic Action Sets and Adversarial Rewards</a> <a href="https://arxiv.org/abs/2004.06248" target="_blank"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Pierre Gaillard, Michal Valko
  <br>  In International Conference on Machine Learning, ICML 2020</li>
    
  <li>  <a href="https://proceedings.mlr.press/v108/aadirupa-saha20a.html" target="_blank">Best-item Learning in Random Utility Models with Subset Choices</a> <a href="https://arxiv.org/abs/2002.07994" target="_blank"> [Arxiv Version]</a>
  <br> Aadirupa Saha, Aditya Gopalan
  <br>  In International Conference on Artificial Intelligence and Statistics, AIStats 2020</li>  
  
  <li>  <a href="http://proceedings.mlr.press/v129/saha20a.html" target="_blank" LINK="red">Polytime Decomposition of Generalized Submodular Base Polytopes with Efficient Sampling</a>
  <br>  Aadirupa Saha
  <br>  In Asian Conference on Machine Learning, ACML 2020</li>
</ul>  
  
<h2 style="color:DarkRed;">2019</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 
  
<ul style="margin:1;padding:1">
   <li>  <a href="http://papers.nips.cc/paper/8384-combinatorial-bandits-with-relative-feedback" target="_blank">Combinatorial Bandits with Relative Feedback</a><a href="https://arxiv.org/abs/1903.00543" target="_blank"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Aditya Gopalan
  <br>  In Neural Information Processing Systems, NeurIPS 2019</li>
  
  <li> <a href="http://proceedings.mlr.press/v115/s20a.html" target="_blank">Be Greedy: How Chromatic Number meets Regret Minimization in Graph Bandits</a>
  <br> Shreyas Seshadri*, Aadirupa Saha*, Chiranjib Bhattacharyya (*Equal Contribution)
  <br> In Uncertainty in Artificial Intelligence, UAI 2019</li>
    
  <li>  <a href="https://proceedings.mlr.press/v89/saha19a" target="_blank">Active Ranking with Subset-wise Preferences</a> <a href="https://arxiv.org/abs/1810.10321" target="_blank"> [Arxiv Version]</a>
  <br> Aadirupa Saha, Aditya Gopalan
  <br>  In International Conference on Artificial Intelligence and Statistics, AIStats 2019</li>  
  
  <li>  <a href="http://proceedings.mlr.press/v98/saha19a.html" target="_blank">PAC Battling Bandits in the Plackett-Luce Model</a> <a href="https://arxiv.org/abs/1808.04008" target="_blank"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Aditya Gopalan
  <br>  In Algorithmic Learning Theory, ALT 2019</li>  
  
  <li>  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5182" target="_blank">How Many Pairwise Preferences Do We Need to Rank A Graph Consistently?</a> <a href="https://arxiv.org/abs/1811.02161" target="_blank"> [Arxiv Version]</a>
  <br>  Aadirupa Saha, Rakesh Shivanna, Chiranjib Bhattacharyya
  <br>  In AAAI Conference on Artificial Intelligence, AAAI 2019</li>  
</ul>  
    
<h2 style="color:DarkRed;">2018</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" /> 

<ul style="margin:1;padding:1">
  <li>  <a href="http://auai.org/uai2018/proceedings/papers/290.pdf" target="_blank">Battle of Bandits</a> 
  <br>  Aadirupa Saha, Aditya Gopalan
  <br> In Uncertainty in Artificial Intelligence, UAI 2018</li>
  
  <li>  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/11669" target="_blank">Online Learning for Structured Loss Spaces</a> <a href="https://arxiv.org/abs/1706.04125" target="_blank"> [Arxiv Version]</a>
  <br>  Siddharth Barman, Aditya Gopalan, Aadirupa Saha (Alphabetical Order)
  <br>  In AAAI Conference on Artificial Intelligence, AAAI 2018</li>  
</ul>  
  
<h2 style="color:DarkRed;">2015</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" />  

<ul style="margin:1;padding:1">
  <li>  <a href="http://proceedings.mlr.press/v37/narasimhanb15.pdf" target="_blank" LINK="red">Consistent Multiclass Algorithms for Complex Performance Measures</a>
  <br>  Harikrishna Narasimhan, Harish Ramaswamy, Aadirupa Saha, Shivani Agarwal
  <br>  In International Conference on Machine Learning, ICML 2015</li>
</ul>  
    
<h2 style="color:DarkRed;">2014</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" />   
  
<ul style="margin:1;padding:1">
  <li>  <a href="https://ieeexplore.ieee.org/document/7033097" target="_blank" LINK="red">Learning Score Systems for Patient Mortality Prediction in Intensive Care Units via Orthogonal Matching Pursuit</a> 
  <br>  Aadirupa Saha, Chandrahas Dewangan, Harikrishna Narasimhan, Sriram Sampath, Shivani Agarwal
  <br>  In International Conference on Machine Learning and Applications, ICMLA 2014</li>
</ul>  
  
<h2 style="color:DarkRed;">2013</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" />   
  
<ul style="margin:1;padding:1">
  <li>  <a href="https://link.springer.com/chapter/10.1007/978-3-642-39693-9_9" target="_blank" LINK="red">Energy Saving Replay Attack Prevention in Clustered Wireless Sensor Networks</a> 
  <br>  Amrita Ghosal, Aadirupa Saha, Sipra Das Bit
  <br>  In Pacific-Asia Workshop on Intelligence and Security Informatics, PAISI 2013</li>
</ul>  
  
<h2 style="color:DarkRed;">2011</h2>  
<hr style="height:1px;border:none;color:#333;background-color:#333;" />   
  
<ul style="margin:1;padding:1">
  <li>  <a href="https://link.springer.com/chapter/10.1007/978-3-642-23641-9_34" target="_blank" LINK="red">Energy-Balancing and Lifetime Enhancement of Wireless
Sensor Network with Archimedes Spiral</a> 
  <br>  Subir Halder, Amrita Ghosal, Aadirupa Saha, Sipra DasBit
  <br>  In International Conference on Ubiquitous Intelligence and Computing, ICUIC 2011</li>
</ul>    
    
<hr style="color:black;">

&nbsp;&nbsp;
<a href="https://aadirupa.github.io/publications#full_publications">[Back to Top]</a> &nbsp;
<a href="https://aadirupa.github.io#selected_publications">[Selected Papers]</a> &nbsp;
<a href="https://aadirupa.github.io/publications#full_publications" target="_blank">[Full List]</a> &nbsp;
<a href="https://scholar.google.co.in/citations?user=7a49tQYAAAAJ&hl=en" target="_blank">[Google Scholar]</a> &nbsp;
<a href="https://dblp.org/pid/14/10003.html" target="_blank">[DBLP]</a> &nbsp;
<a href="https://arxiv.org/find/all/1/au:+saha_aadirupa/0/1/0/all/0/1" target="_blank">[arXiv]</a>   

</body>
</html>
